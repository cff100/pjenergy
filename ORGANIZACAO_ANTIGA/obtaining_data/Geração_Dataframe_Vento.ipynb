{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cff100/pjenergy/blob/main/Obten%C3%A7%C3%A3o_de_dados/Gera%C3%A7%C3%A3o_Dataframe_Vento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' INFO\n",
        "Gera dataframes .csv a partir dos arquivos .nc\n",
        "Na pasta data/dataframe_ventos há os arquivos .csv gerados (dataframes_ventos_por_ano)\n",
        "Posteriormente os .csv dataframes_ventos_por_ano foram unidos e separados por plataforma (dataframes_ventos_por_plataforma).\n",
        "É assim que eles dão utilizados nos outros códigos.\n",
        "'''\n",
        "\n",
        "\n",
        "# IMPORTAÇÕES E INSTALAÇÕES\n",
        "\n",
        "import math\n",
        "import xarray as xr\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta"
      ],
      "metadata": {
        "id": "PULT2WOvX_WI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AMi3iYFhybOZ",
        "outputId": "b58383ad-4a34-4da6-94a0-d8a8bd523e81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (2.0.0)\n"
          ]
        }
      ],
      "source": [
        "# CONSTANTES, INPUTS E FUNÇÕES\n",
        "\n",
        "# Constantes\n",
        "PA = 101.325  # Pressão atmosférica ao nível do mar em kPa\n",
        "k = 1.21e-5   # Constante em s²/m²\n",
        "g = 9.81      # Aceleração gravitacional em m/s²\n",
        "\n",
        "# Função para calcular a altura a partir da pressão\n",
        "def calcular_altura(PA, k, P_h, g):\n",
        "  # P_h: Pressão a uma altura h (em KPa)\n",
        "  altura = -math.log(P_h / PA) / (k * g)\n",
        "  return altura\n",
        "\n",
        "# Função para converter horário de Brasília para UTC\n",
        "def brasilia_para_utc(horario_brasilia):\n",
        "  brasilia_time = datetime.strptime(horario_brasilia, '%H:%M')\n",
        "  utc_time = brasilia_time + timedelta(hours=3)\n",
        "  return utc_time.strftime('%H:%M')\n",
        "\n",
        "\n",
        "# Função para converter temperatura de Kelvin para Celsius\n",
        "def kelvin_para_celsius(kelvin):\n",
        "  return kelvin - 273.15\n",
        "\n",
        "# Função para verificar se a data é válida\n",
        "def data_valida(dia, mes, ano):\n",
        "  try:\n",
        "      datetime(ano, mes, dia)\n",
        "      return True\n",
        "  except ValueError:\n",
        "      return False\n",
        "\n",
        "\n",
        "def estacao_do_ano(dia, mes):\n",
        "  \"\"\"\n",
        "  Retorna a estação do ano no hemisfério sul com base na data fornecida.\n",
        "\n",
        "  Parâmetros:\n",
        "  dia (int): O dia do mês.\n",
        "  mes (int): O mês (1-12).\n",
        "\n",
        "  Retorna:\n",
        "  str: A estação correspondente ('Verão', 'Outono', 'Inverno', 'Primavera').\n",
        "  \"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "  Note que os dias em que se iniciam e terminam uma estação variam de ano em ano.\n",
        "  Contudo, a diferença máxima é de dois dias então foram consideradas como padrão as datas de 2023.\n",
        "  \"\"\"\n",
        "\n",
        "  # Verão: 21 de Dezembro a 20 de Março\n",
        "  if (mes == 12 and dia >= 21) or (1 <= mes <= 2) or (mes == 3 and dia <= 20):\n",
        "      return 'Verão'\n",
        "  # Outono: 21 de Março a 20 de Junho\n",
        "  elif (mes == 3 and dia >= 21) or (4 <= mes <= 5) or (mes == 6 and dia <= 20):\n",
        "      return 'Outono'\n",
        "  # Inverno: 21 de Junho a 22 de Setembro\n",
        "  elif (mes == 6 and dia >= 21) or (7 <= mes <= 8) or (mes == 9 and dia <= 22):\n",
        "      return 'Inverno'\n",
        "  # Primavera: 23 de Setembro a 20 de Dezembro\n",
        "  elif (mes == 9 and dia >= 23) or (10 <= mes <= 11) or (mes == 12 and dia <= 20):\n",
        "      return 'Primavera'\n",
        "\n",
        "# Níveis de pressão em KPa\n",
        "niveis_pressao = [90.0, 92.5, 95.0, 97.5, 100.0]\n",
        "\n",
        "# Horas\n",
        "horas = ['03:00', '09:00', '15:00', '21:00']\n",
        "\n",
        "# Dias, meses e anos\n",
        "anos = [ano for ano in range(2010, 2024)]\n",
        "meses = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
        "dias = [d for d in range(1, 32)]\n",
        "\n",
        "\n",
        "# Coordenadas das plataformas\n",
        "plataformas = {\n",
        "    'NAMORADO 2 (PNA-2)': (-22.45073, -40.41175),\n",
        "    'PETROBRAS 26 (P-26)': (-22.4684, -40.02869),\n",
        "    'PETROBRAS 32 (P-32)': (-22.2051, -40.1431),\n",
        "    'PETROBRAS 37 (P-37)': (-22.4868, -40.09779),\n",
        "    'PETROBRAS IX': (-22.57358, -40.82192),\n",
        "    'PETROBRAS XIX': (-22.3927, -40.05438),\n",
        "    'PETROBRAS XXXIII': (-22.37, -40.0267),\n",
        "    'VERMELHO 1 (PVM-1)': (-22.16065, -40.27872),\n",
        "    'VERMELHO 2 (PVM-2)': (-22.17535, -40.29147),\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de arquivos .nc de diferentes anos\n",
        "arquivos_era5 = {'Era5_Vento_CAMPOS(2010-2011).nc':[2010,2011], 'Era5_Vento_CAMPOS(2012-2013).nc':[2012,2013],\n",
        "                'Era5_Vento_CAMPOS(2014-2015).nc':[2014,2015], 'Era5_Vento_CAMPOS(2016-2017).nc':[2016,2017],\n",
        "                 'Era5_Vento_CAMPOS(2018-2019).nc':[2018,2019], 'Era5_Vento_CAMPOS(2020-2021).nc':[2020,2021],\n",
        "                 'Era5_Vento_CAMPOS(2022-2023).nc':[2022,2023]\n",
        "}\n",
        "\n",
        "lista_arq_era5 = list(arquivos_era5.keys())\n",
        "\n",
        "lista_arq_csv = [nome[:-3] + '.csv' for nome in lista_arq_era5]\n"
      ],
      "metadata": {
        "id": "m8UFjBokYDdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "GGNF70qDz4lk",
        "outputId": "3fcf7469-ee7f-428a-c33b-d125b063fc13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data inválida: 29/2/2010\n",
            "Data inválida: 30/2/2010\n",
            "Data inválida: 31/2/2010\n",
            "Data inválida: 31/4/2010\n",
            "Data inválida: 31/6/2010\n",
            "Data inválida: 31/9/2010\n",
            "Data inválida: 31/11/2010\n",
            "Data inválida: 29/2/2011\n",
            "Data inválida: 30/2/2011\n",
            "Data inválida: 31/2/2011\n",
            "Data inválida: 31/4/2011\n",
            "Data inválida: 31/6/2011\n",
            "Data inválida: 31/9/2011\n",
            "Data inválida: 31/11/2011\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "\"None of [Index(['Ano', 'Mês', 'Dia'], dtype='object')] are in the [columns]\"",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1720dc7f599f>\u001b[0m in \u001b[0;36m<cell line: 152>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;31m# Criar a coluna 'Data' a partir das colunas 'Ano', 'Mês' e 'Dia'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m \u001b[0mcombinado_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Data'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombinado_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Ano'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Mês'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Dia'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Ano'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Mês'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'month'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Dia'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'day'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Rename columns to match expected names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;31m# Remover as colunas 'Ano', 'Mês' e 'Dia'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6249\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Ano', 'Mês', 'Dia'], dtype='object')] are in the [columns]\""
          ]
        }
      ],
      "source": [
        "'''\n",
        "Anos 2010-2011 --------------------------------------------------------------------\n",
        "'''\n",
        "\n",
        "i = 0\n",
        "\n",
        "arquivo_nc = lista_arq_era5[i]\n",
        "arquivo_csv = lista_arq_csv[i]\n",
        "\n",
        "# Carrega o arquivo NetCDF usando xarray\n",
        "ds = xr.open_dataset(arquivo_nc, engine='h5netcdf')\n",
        "\n",
        "# Renomeia a coordenada 'valid_time' para 'time'\n",
        "ds = ds.rename({'valid_time': 'time'})\n",
        "\n",
        "anos = arquivos_era5[arquivo_nc]\n",
        "\n",
        "ano_df = pd.DataFrame()\n",
        "\n",
        "# Nomeia o índice do DataFrame\n",
        "ano_df.index.name = 'Índice'\n",
        "\n",
        "\n",
        "# Loop sobre cada ano\n",
        "for ano in anos:\n",
        "\n",
        "  # Cria um DataFrame vazio para armazenar os resultados combinados dos meses\n",
        "  mes_df = pd.DataFrame()\n",
        "\n",
        "  # Loop sobre cada mês\n",
        "  for mes in meses:\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados combinados dos dias\n",
        "    dia_df = pd.DataFrame()\n",
        "\n",
        "    # Loop sobre cada dia\n",
        "    for dia in dias:\n",
        "\n",
        "      # Verifica se a data existe\n",
        "      if not data_valida(dia, mes, ano):\n",
        "        print(f\"Data inválida: {dia}/{mes}/{ano}\")\n",
        "        continue  # Pula esta iteração se o dia não for válido\n",
        "\n",
        "      # Cria um DataFrame vazio para armazenar os resultados combinados dos níveis de pressão\n",
        "      nivel_df = pd.DataFrame()\n",
        "\n",
        "      # Loop sobre cada nível de pressão\n",
        "      for nivel in niveis_pressao:\n",
        "\n",
        "        # Cria um DataFrame vazio para armazenar os resultados combinados das horas\n",
        "        hora_df = pd.DataFrame()\n",
        "\n",
        "        # Loop sobre cada hora\n",
        "        for hora in horas:\n",
        "\n",
        "          #Função para obter a hora UTC (Tempo Universal Coordenado) a partir da hora de Brasília\n",
        "          hora_utc = brasilia_para_utc(hora)\n",
        "\n",
        "          # Filtros\n",
        "          filtra_hora = ds.time.dt.strftime('%H:%M') == hora_utc\n",
        "          filtra_nivel = ds['pressure_level'] == nivel*10\n",
        "          filtra_dia = ds.time.dt.day == dia\n",
        "          filtra_mes = ds.time.dt.month == mes\n",
        "          filtra_ano = ds.time.dt.year == ano\n",
        "\n",
        "          # Aplicação dos filtros com where\n",
        "          ds_f = ds.where(filtra_hora & filtra_nivel & filtra_dia & filtra_mes & filtra_ano, drop=True)\n",
        "\n",
        "          # DataArray das velocidades\n",
        "          u = ds_f['u']\n",
        "          v = ds_f['v']\n",
        "\n",
        "          # Calcula a velocidade resultante do vento (wspd)\n",
        "          wspd = (u**2 + v**2)**0.5\n",
        "\n",
        "          # DataArray das temperaturas\n",
        "          temp = ds_f['t']\n",
        "\n",
        "          # Cria um DataFrame vazio para armazenar os resultados combinados das plataformas\n",
        "          unico_df = pd.DataFrame()\n",
        "\n",
        "          # Loop sobre cada plataforma\n",
        "          for plataforma, (lat, lon) in plataformas.items():\n",
        "\n",
        "            # Interpola o valor das componentes da velocidade do vento\n",
        "            vento_u = u.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "            vento_v = v.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "            # Interpola o valor da resultante da velocidade do vento\n",
        "            vento_resultante = wspd.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "\n",
        "            # Interpola o valor da temperatura em Kelvin\n",
        "            temp_kelvin = temp.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "            # Converte a temperatura para Celsius\n",
        "            temp_celsius = kelvin_para_celsius(temp_kelvin)\n",
        "\n",
        "            # Chama a função que determina a estação do ano a partir da data\n",
        "            estacao = estacao_do_ano(dia, mes)\n",
        "\n",
        "            # Adiciona uma linha com cada coluna para cada plataforma\n",
        "            unico_df = pd.concat([unico_df, pd.DataFrame({\n",
        "                      'Plataforma': plataforma,\n",
        "                      'Velocidade_Vento_u_m/s': vento_u,\n",
        "                      'Velocidade_Vento_v_m/s': vento_v,\n",
        "                      'Velocidade_Vento_resultante_m/s': vento_resultante,\n",
        "                      'Temperatura_K': temp_kelvin,\n",
        "                      'Temperatura_C': temp_celsius,\n",
        "                      'Dia': dia,\n",
        "                      'Mês': mes,\n",
        "                      'Ano': ano,\n",
        "                      'Estação_do_Ano': estacao\n",
        "                  }, index=[0])], ignore_index=True)\n",
        "\n",
        "\n",
        "          #Adiciona as colunas de hora\n",
        "          unico_df['Horário_Brasília'] = hora\n",
        "          unico_df['Horário_UTC'] = hora_utc\n",
        "\n",
        "          # Adiciona o DataFrame unico atual ao DataFrame da hora atual\n",
        "          hora_df = pd.concat([hora_df, unico_df], ignore_index=True)\n",
        "\n",
        "        # Adiciona a coluna de pressão\n",
        "        hora_df['Nível_de_Pressão_hPa'] = int(nivel*10)\n",
        "\n",
        "        # Calcula a altura correspondente ao nível de pressão atual\n",
        "        altura = calcular_altura(PA, k, nivel, g)\n",
        "        # Adiciona a coluna de altura\n",
        "        hora_df['Altitude_m'] = altura\n",
        "\n",
        "        # Adiciona o DataFrame da hora atual ao DataFrame de nível da pressão atual\n",
        "        nivel_df = pd.concat([nivel_df, hora_df], ignore_index=True)\n",
        "\n",
        "      # Adiciona a coluna de dia\n",
        "      nivel_df['Dia'] = dia\n",
        "      # Adiciona o DataFrame do nível de pressão atual ao DataFrame do dia atual\n",
        "      dia_df = pd.concat([dia_df, nivel_df], ignore_index=True)\n",
        "\n",
        "    # Adiciona a coluna de mês\n",
        "    dia_df['Mês'] = mes\n",
        "    # Adiciona o DataFrame do dia atual ao DataFrame do mês atual\n",
        "    mes_df = pd.concat([mes_df, dia_df], ignore_index=True)\n",
        "\n",
        "  # Adiciona a coluna de ano\n",
        "  mes_df['Ano'] = ano\n",
        "  # Adiciona o DataFrame do nível do mês atual ao DataFrame combinado\n",
        "  ano_df = pd.concat([ano_df, mes_df], ignore_index=True)\n",
        "\n",
        "  # Fecha o arquivo NetCDF\n",
        "  ds.close()\n",
        "\n",
        "\n",
        "\n",
        "# Criar a coluna 'Data' a partir das colunas 'Ano', 'Mês' e 'Dia'\n",
        "ano_df['Data'] = pd.to_datetime(ano_df[['Ano', 'Mês', 'Dia']].rename(columns={'Ano':'year', 'Mês':'month', 'Dia':'day'}), errors='coerce') # Rename columns to match expected names\n",
        "\n",
        "# Remover as colunas 'Ano', 'Mês' e 'Dia'\n",
        "ano_df = ano_df.drop(columns=['Ano', 'Mês', 'Dia'])\n",
        "\n",
        "# Ajusta a ordem das colunas\n",
        "ano_df = ano_df[['Plataforma', 'Nível_de_Pressão_hPa', 'Altitude_m', 'Estação_do_Ano', 'Data', 'Horário_Brasília', 'Horário_UTC',\n",
        "                           'Velocidade_Vento_u_m/s', 'Velocidade_Vento_v_m/s', 'Velocidade_Vento_resultante_m/s', 'Temperatura_K', 'Temperatura_C']]\n",
        "\n",
        "# Salvar o DataFrame combinado como um arquivo CSV\n",
        "ano_df.to_csv(arquivo_csv, encoding='utf-8', index=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6iJNVIp7nmF",
        "outputId": "3e1911de-7827-492f-b983-4b70043eeff6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data inválida: 30/2/2012\n",
            "Data inválida: 31/2/2012\n",
            "Data inválida: 31/4/2012\n",
            "Data inválida: 31/6/2012\n",
            "Data inválida: 31/9/2012\n",
            "Data inválida: 31/11/2012\n",
            "Data inválida: 29/2/2013\n",
            "Data inválida: 30/2/2013\n",
            "Data inválida: 31/2/2013\n",
            "Data inválida: 31/4/2013\n",
            "Data inválida: 31/6/2013\n",
            "Data inválida: 31/9/2013\n",
            "Data inválida: 31/11/2013\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Anos 2012-2013 --------------------------------------------------------------------\n",
        "'''\n",
        "\n",
        "i = 1\n",
        "\n",
        "arquivo_nc = lista_arq_era5[i]\n",
        "arquivo_csv = lista_arq_csv[i]\n",
        "\n",
        "# Carrega o arquivo NetCDF usando xarray\n",
        "ds = xr.open_dataset(arquivo_nc, engine='h5netcdf')\n",
        "\n",
        "# Renomeia a coordenada 'valid_time' para 'time'\n",
        "ds = ds.rename({'valid_time': 'time'})\n",
        "\n",
        "anos = arquivos_era5[arquivo_nc]\n",
        "\n",
        "ano_df = pd.DataFrame()\n",
        "\n",
        "# Nomeia o índice do DataFrame\n",
        "ano_df.index.name = 'Índice'\n",
        "\n",
        "\n",
        "# Loop sobre cada ano\n",
        "for ano in anos:\n",
        "\n",
        "  # Cria um DataFrame vazio para armazenar os resultados combinados dos meses\n",
        "  mes_df = pd.DataFrame()\n",
        "\n",
        "  # Loop sobre cada mês\n",
        "  for mes in meses:\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados combinados dos dias\n",
        "    dia_df = pd.DataFrame()\n",
        "\n",
        "    # Loop sobre cada dia\n",
        "    for dia in dias:\n",
        "\n",
        "      # Verifica se a data existe\n",
        "      if not data_valida(dia, mes, ano):\n",
        "        print(f\"Data inválida: {dia}/{mes}/{ano}\")\n",
        "        continue  # Pula esta iteração se o dia não for válido\n",
        "\n",
        "      # Cria um DataFrame vazio para armazenar os resultados combinados dos níveis de pressão\n",
        "      nivel_df = pd.DataFrame()\n",
        "\n",
        "      # Loop sobre cada nível de pressão\n",
        "      for nivel in niveis_pressao:\n",
        "\n",
        "        # Cria um DataFrame vazio para armazenar os resultados combinados das horas\n",
        "        hora_df = pd.DataFrame()\n",
        "\n",
        "        # Loop sobre cada hora\n",
        "        for hora in horas:\n",
        "\n",
        "          #Função para obter a hora UTC (Tempo Universal Coordenado) a partir da hora de Brasília\n",
        "          hora_utc = brasilia_para_utc(hora)\n",
        "\n",
        "          # Filtros\n",
        "          filtra_hora = ds.time.dt.strftime('%H:%M') == hora_utc\n",
        "          filtra_nivel = ds['pressure_level'] == nivel*10\n",
        "          filtra_dia = ds.time.dt.day == dia\n",
        "          filtra_mes = ds.time.dt.month == mes\n",
        "          filtra_ano = ds.time.dt.year == ano\n",
        "\n",
        "          # Aplicação dos filtros com where\n",
        "          ds_f = ds.where(filtra_hora & filtra_nivel & filtra_dia & filtra_mes & filtra_ano, drop=True)\n",
        "\n",
        "          # DataArray das velocidades\n",
        "          u = ds_f['u']\n",
        "          v = ds_f['v']\n",
        "\n",
        "          # Calcula a velocidade resultante do vento (wspd)\n",
        "          wspd = (u**2 + v**2)**0.5\n",
        "\n",
        "          # DataArray das temperaturas\n",
        "          temp = ds_f['t']\n",
        "\n",
        "          # Cria um DataFrame vazio para armazenar os resultados combinados das plataformas\n",
        "          unico_df = pd.DataFrame()\n",
        "\n",
        "          # Loop sobre cada plataforma\n",
        "          for plataforma, (lat, lon) in plataformas.items():\n",
        "\n",
        "            # Interpola o valor das componentes da velocidade do vento\n",
        "            vento_u = u.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "            vento_v = v.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "            # Interpola o valor da resultante da velocidade do vento\n",
        "            vento_resultante = wspd.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "\n",
        "            # Interpola o valor da temperatura em Kelvin\n",
        "            temp_kelvin = temp.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "            # Converte a temperatura para Celsius\n",
        "            temp_celsius = kelvin_para_celsius(temp_kelvin)\n",
        "\n",
        "            # Chama a função que determina a estação do ano a partir da data\n",
        "            estacao = estacao_do_ano(dia, mes)\n",
        "\n",
        "            # Adiciona uma linha com cada coluna para cada plataforma\n",
        "            unico_df = pd.concat([unico_df, pd.DataFrame({\n",
        "                      'Plataforma': plataforma,\n",
        "                      'Velocidade_Vento_u_m/s': vento_u,\n",
        "                      'Velocidade_Vento_v_m/s': vento_v,\n",
        "                      'Velocidade_Vento_resultante_m/s': vento_resultante,\n",
        "                      'Temperatura_K': temp_kelvin,\n",
        "                      'Temperatura_C': temp_celsius,\n",
        "                      'Dia': dia,\n",
        "                      'Mês': mes,\n",
        "                      'Ano': ano,\n",
        "                      'Estação_do_Ano': estacao\n",
        "                  }, index=[0])], ignore_index=True)\n",
        "\n",
        "\n",
        "          #Adiciona as colunas de hora\n",
        "          unico_df['Horário_Brasília'] = hora\n",
        "          unico_df['Horário_UTC'] = hora_utc\n",
        "\n",
        "          # Adiciona o DataFrame unico atual ao DataFrame da hora atual\n",
        "          hora_df = pd.concat([hora_df, unico_df], ignore_index=True)\n",
        "\n",
        "        # Adiciona a coluna de pressão\n",
        "        hora_df['Nível_de_Pressão_hPa'] = int(nivel*10)\n",
        "\n",
        "        # Calcula a altura correspondente ao nível de pressão atual\n",
        "        altura = calcular_altura(PA, k, nivel, g)\n",
        "        # Adiciona a coluna de altura\n",
        "        hora_df['Altitude_m'] = altura\n",
        "\n",
        "        # Adiciona o DataFrame da hora atual ao DataFrame de nível da pressão atual\n",
        "        nivel_df = pd.concat([nivel_df, hora_df], ignore_index=True)\n",
        "\n",
        "      # Adiciona a coluna de dia\n",
        "      nivel_df['Dia'] = dia\n",
        "      # Adiciona o DataFrame do nível de pressão atual ao DataFrame do dia atual\n",
        "      dia_df = pd.concat([dia_df, nivel_df], ignore_index=True)\n",
        "\n",
        "    # Adiciona a coluna de mês\n",
        "    dia_df['Mês'] = mes\n",
        "    # Adiciona o DataFrame do dia atual ao DataFrame do mês atual\n",
        "    mes_df = pd.concat([mes_df, dia_df], ignore_index=True)\n",
        "\n",
        "  # Adiciona a coluna de ano\n",
        "  mes_df['Ano'] = ano\n",
        "  # Adiciona o DataFrame do nível do mês atual ao DataFrame combinado\n",
        "  ano_df = pd.concat([ano_df, mes_df], ignore_index=True)\n",
        "\n",
        "  # Fecha o arquivo NetCDF\n",
        "  ds.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Criar a coluna 'Data' a partir das colunas 'Ano', 'Mês' e 'Dia'\n",
        "ano_df['Data'] = pd.to_datetime(ano_df[['Ano', 'Mês', 'Dia']].rename(columns={'Ano':'year', 'Mês':'month', 'Dia':'day'}), errors='coerce') # Rename columns to match expected names\n",
        "\n",
        "# Remover as colunas 'Ano', 'Mês' e 'Dia'\n",
        "ano_df = ano_df.drop(columns=['Ano', 'Mês', 'Dia'])\n",
        "\n",
        "# Ajusta a ordem das colunas\n",
        "ano_df = ano_df[['Plataforma', 'Nível_de_Pressão_hPa', 'Altitude_m', 'Estação_do_Ano', 'Data', 'Horário_Brasília', 'Horário_UTC',\n",
        "                           'Velocidade_Vento_u_m/s', 'Velocidade_Vento_v_m/s', 'Velocidade_Vento_resultante_m/s', 'Temperatura_K', 'Temperatura_C']]\n",
        "\n",
        "# Salvar o DataFrame combinado como um arquivo CSV\n",
        "ano_df.to_csv(arquivo_csv, encoding='utf-8', index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWLg0PN8jbre",
        "outputId": "103be29c-a13f-461c-eff8-525fdab0764d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data inválida: 29/2/2014\n",
            "Data inválida: 30/2/2014\n",
            "Data inválida: 31/2/2014\n",
            "Data inválida: 31/4/2014\n",
            "Data inválida: 31/6/2014\n",
            "Data inválida: 31/9/2014\n",
            "Data inválida: 31/11/2014\n",
            "Data inválida: 29/2/2015\n",
            "Data inválida: 30/2/2015\n",
            "Data inválida: 31/2/2015\n",
            "Data inválida: 31/4/2015\n",
            "Data inválida: 31/6/2015\n",
            "Data inválida: 31/9/2015\n",
            "Data inválida: 31/11/2015\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Anos 2014-2015 --------------------------------------------------------------------\n",
        "'''\n",
        "\n",
        "i = 2\n",
        "\n",
        "arquivo_nc = lista_arq_era5[i]\n",
        "arquivo_csv = lista_arq_csv[i]\n",
        "\n",
        "# Carrega o arquivo NetCDF usando xarray\n",
        "ds = xr.open_dataset(arquivo_nc, engine='h5netcdf')\n",
        "\n",
        "# Renomeia a coordenada 'valid_time' para 'time'\n",
        "ds = ds.rename({'valid_time': 'time'})\n",
        "\n",
        "anos = arquivos_era5[arquivo_nc]\n",
        "\n",
        "ano_df = pd.DataFrame()\n",
        "\n",
        "# Nomeia o índice do DataFrame\n",
        "ano_df.index.name = 'Índice'\n",
        "\n",
        "\n",
        "# Loop sobre cada ano\n",
        "for ano in anos:\n",
        "\n",
        "  # Cria um DataFrame vazio para armazenar os resultados combinados dos meses\n",
        "  mes_df = pd.DataFrame()\n",
        "\n",
        "  # Loop sobre cada mês\n",
        "  for mes in meses:\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados combinados dos dias\n",
        "    dia_df = pd.DataFrame()\n",
        "\n",
        "    # Loop sobre cada dia\n",
        "    for dia in dias:\n",
        "\n",
        "      # Verifica se a data existe\n",
        "      if not data_valida(dia, mes, ano):\n",
        "        print(f\"Data inválida: {dia}/{mes}/{ano}\")\n",
        "        continue  # Pula esta iteração se o dia não for válido\n",
        "\n",
        "      # Cria um DataFrame vazio para armazenar os resultados combinados dos níveis de pressão\n",
        "      nivel_df = pd.DataFrame()\n",
        "\n",
        "      # Loop sobre cada nível de pressão\n",
        "      for nivel in niveis_pressao:\n",
        "\n",
        "        # Cria um DataFrame vazio para armazenar os resultados combinados das horas\n",
        "        hora_df = pd.DataFrame()\n",
        "\n",
        "        # Loop sobre cada hora\n",
        "        for hora in horas:\n",
        "\n",
        "          #Função para obter a hora UTC (Tempo Universal Coordenado) a partir da hora de Brasília\n",
        "          hora_utc = brasilia_para_utc(hora)\n",
        "\n",
        "          # Filtros\n",
        "          filtra_hora = ds.time.dt.strftime('%H:%M') == hora_utc\n",
        "          filtra_nivel = ds['pressure_level'] == nivel*10\n",
        "          filtra_dia = ds.time.dt.day == dia\n",
        "          filtra_mes = ds.time.dt.month == mes\n",
        "          filtra_ano = ds.time.dt.year == ano\n",
        "\n",
        "          # Aplicação dos filtros com where\n",
        "          ds_f = ds.where(filtra_hora & filtra_nivel & filtra_dia & filtra_mes & filtra_ano, drop=True)\n",
        "\n",
        "          # DataArray das velocidades\n",
        "          u = ds_f['u']\n",
        "          v = ds_f['v']\n",
        "\n",
        "          # Calcula a velocidade resultante do vento (wspd)\n",
        "          wspd = (u**2 + v**2)**0.5\n",
        "\n",
        "          # DataArray das temperaturas\n",
        "          temp = ds_f['t']\n",
        "\n",
        "          # Cria um DataFrame vazio para armazenar os resultados combinados das plataformas\n",
        "          unico_df = pd.DataFrame()\n",
        "\n",
        "          # Loop sobre cada plataforma\n",
        "          for plataforma, (lat, lon) in plataformas.items():\n",
        "\n",
        "            # Interpola o valor das componentes da velocidade do vento\n",
        "            vento_u = u.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "            vento_v = v.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "            # Interpola o valor da resultante da velocidade do vento\n",
        "            vento_resultante = wspd.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "\n",
        "            # Interpola o valor da temperatura em Kelvin\n",
        "            temp_kelvin = temp.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "            # Converte a temperatura para Celsius\n",
        "            temp_celsius = kelvin_para_celsius(temp_kelvin)\n",
        "\n",
        "            # Chama a função que determina a estação do ano a partir da data\n",
        "            estacao = estacao_do_ano(dia, mes)\n",
        "\n",
        "            # Adiciona uma linha com cada coluna para cada plataforma\n",
        "            unico_df = pd.concat([unico_df, pd.DataFrame({\n",
        "                      'Plataforma': plataforma,\n",
        "                      'Velocidade_Vento_u_m/s': vento_u,\n",
        "                      'Velocidade_Vento_v_m/s': vento_v,\n",
        "                      'Velocidade_Vento_resultante_m/s': vento_resultante,\n",
        "                      'Temperatura_K': temp_kelvin,\n",
        "                      'Temperatura_C': temp_celsius,\n",
        "                      'Dia': dia,\n",
        "                      'Mês': mes,\n",
        "                      'Ano': ano,\n",
        "                      'Estação_do_Ano': estacao\n",
        "                  }, index=[0])], ignore_index=True)\n",
        "\n",
        "\n",
        "          #Adiciona as colunas de hora\n",
        "          unico_df['Horário_Brasília'] = hora\n",
        "          unico_df['Horário_UTC'] = hora_utc\n",
        "\n",
        "          # Adiciona o DataFrame unico atual ao DataFrame da hora atual\n",
        "          hora_df = pd.concat([hora_df, unico_df], ignore_index=True)\n",
        "\n",
        "        # Adiciona a coluna de pressão\n",
        "        hora_df['Nível_de_Pressão_hPa'] = int(nivel*10)\n",
        "\n",
        "        # Calcula a altura correspondente ao nível de pressão atual\n",
        "        altura = calcular_altura(PA, k, nivel, g)\n",
        "        # Adiciona a coluna de altura\n",
        "        hora_df['Altitude_m'] = altura\n",
        "\n",
        "        # Adiciona o DataFrame da hora atual ao DataFrame de nível da pressão atual\n",
        "        nivel_df = pd.concat([nivel_df, hora_df], ignore_index=True)\n",
        "\n",
        "      # Adiciona a coluna de dia\n",
        "      nivel_df['Dia'] = dia\n",
        "      # Adiciona o DataFrame do nível de pressão atual ao DataFrame do dia atual\n",
        "      dia_df = pd.concat([dia_df, nivel_df], ignore_index=True)\n",
        "\n",
        "    # Adiciona a coluna de mês\n",
        "    dia_df['Mês'] = mes\n",
        "    # Adiciona o DataFrame do dia atual ao DataFrame do mês atual\n",
        "    mes_df = pd.concat([mes_df, dia_df], ignore_index=True)\n",
        "\n",
        "  # Adiciona a coluna de ano\n",
        "  mes_df['Ano'] = ano\n",
        "  # Adiciona o DataFrame do nível do mês atual ao DataFrame combinado\n",
        "  ano_df = pd.concat([ano_df, mes_df], ignore_index=True)\n",
        "\n",
        "  # Fecha o arquivo NetCDF\n",
        "  ds.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Criar a coluna 'Data' a partir das colunas 'Ano', 'Mês' e 'Dia'\n",
        "ano_df['Data'] = pd.to_datetime(ano_df[['Ano', 'Mês', 'Dia']].rename(columns={'Ano':'year', 'Mês':'month', 'Dia':'day'}), errors='coerce') # Rename columns to match expected names\n",
        "\n",
        "# Remover as colunas 'Ano', 'Mês' e 'Dia'\n",
        "ano_df = ano_df.drop(columns=['Ano', 'Mês', 'Dia'])\n",
        "\n",
        "# Ajusta a ordem das colunas\n",
        "ano_df = ano_df[['Plataforma', 'Nível_de_Pressão_hPa', 'Altitude_m', 'Estação_do_Ano', 'Data', 'Horário_Brasília', 'Horário_UTC',\n",
        "                           'Velocidade_Vento_u_m/s', 'Velocidade_Vento_v_m/s', 'Velocidade_Vento_resultante_m/s', 'Temperatura_K', 'Temperatura_C']]\n",
        "\n",
        "# Salvar o DataFrame combinado como um arquivo CSV\n",
        "ano_df.to_csv(arquivo_csv, encoding='utf-8', index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfPbtZvyjj2X",
        "outputId": "8e8b6cec-e5c5-4618-ccc1-3e6292a59dc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data inválida: 30/2/2016\n",
            "Data inválida: 31/2/2016\n",
            "Data inválida: 31/4/2016\n",
            "Data inválida: 31/6/2016\n",
            "Data inválida: 31/9/2016\n",
            "Data inválida: 31/11/2016\n",
            "Data inválida: 29/2/2017\n",
            "Data inválida: 30/2/2017\n",
            "Data inválida: 31/2/2017\n",
            "Data inválida: 31/4/2017\n",
            "Data inválida: 31/6/2017\n",
            "Data inválida: 31/9/2017\n",
            "Data inválida: 31/11/2017\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Anos 2016-2017 --------------------------------------------------------------------\n",
        "'''\n",
        "\n",
        "i = 3\n",
        "\n",
        "arquivo_nc = lista_arq_era5[i]\n",
        "arquivo_csv = lista_arq_csv[i]\n",
        "\n",
        "# Carrega o arquivo NetCDF usando xarray\n",
        "ds = xr.open_dataset(arquivo_nc, engine='h5netcdf')\n",
        "\n",
        "# Renomeia a coordenada 'valid_time' para 'time'\n",
        "ds = ds.rename({'valid_time': 'time'})\n",
        "\n",
        "anos = arquivos_era5[arquivo_nc]\n",
        "\n",
        "ano_df = pd.DataFrame()\n",
        "\n",
        "# Nomeia o índice do DataFrame\n",
        "ano_df.index.name = 'Índice'\n",
        "\n",
        "\n",
        "# Loop sobre cada ano\n",
        "for ano in anos:\n",
        "\n",
        "  # Cria um DataFrame vazio para armazenar os resultados combinados dos meses\n",
        "  mes_df = pd.DataFrame()\n",
        "\n",
        "  # Loop sobre cada mês\n",
        "  for mes in meses:\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados combinados dos dias\n",
        "    dia_df = pd.DataFrame()\n",
        "\n",
        "    # Loop sobre cada dia\n",
        "    for dia in dias:\n",
        "\n",
        "      # Verifica se a data existe\n",
        "      if not data_valida(dia, mes, ano):\n",
        "        print(f\"Data inválida: {dia}/{mes}/{ano}\")\n",
        "        continue  # Pula esta iteração se o dia não for válido\n",
        "\n",
        "      # Cria um DataFrame vazio para armazenar os resultados combinados dos níveis de pressão\n",
        "      nivel_df = pd.DataFrame()\n",
        "\n",
        "      # Loop sobre cada nível de pressão\n",
        "      for nivel in niveis_pressao:\n",
        "\n",
        "        # Cria um DataFrame vazio para armazenar os resultados combinados das horas\n",
        "        hora_df = pd.DataFrame()\n",
        "\n",
        "        # Loop sobre cada hora\n",
        "        for hora in horas:\n",
        "\n",
        "          #Função para obter a hora UTC (Tempo Universal Coordenado) a partir da hora de Brasília\n",
        "          hora_utc = brasilia_para_utc(hora)\n",
        "\n",
        "          # Filtros\n",
        "          filtra_hora = ds.time.dt.strftime('%H:%M') == hora_utc\n",
        "          filtra_nivel = ds['pressure_level'] == nivel*10\n",
        "          filtra_dia = ds.time.dt.day == dia\n",
        "          filtra_mes = ds.time.dt.month == mes\n",
        "          filtra_ano = ds.time.dt.year == ano\n",
        "\n",
        "          # Aplicação dos filtros com where\n",
        "          ds_f = ds.where(filtra_hora & filtra_nivel & filtra_dia & filtra_mes & filtra_ano, drop=True)\n",
        "\n",
        "          # DataArray das velocidades\n",
        "          u = ds_f['u']\n",
        "          v = ds_f['v']\n",
        "\n",
        "          # Calcula a velocidade resultante do vento (wspd)\n",
        "          wspd = (u**2 + v**2)**0.5\n",
        "\n",
        "          # DataArray das temperaturas\n",
        "          temp = ds_f['t']\n",
        "\n",
        "          # Cria um DataFrame vazio para armazenar os resultados combinados das plataformas\n",
        "          unico_df = pd.DataFrame()\n",
        "\n",
        "          # Loop sobre cada plataforma\n",
        "          for plataforma, (lat, lon) in plataformas.items():\n",
        "\n",
        "            # Interpola o valor das componentes da velocidade do vento\n",
        "            vento_u = u.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "            vento_v = v.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "            # Interpola o valor da resultante da velocidade do vento\n",
        "            vento_resultante = wspd.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "\n",
        "            # Interpola o valor da temperatura em Kelvin\n",
        "            temp_kelvin = temp.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "            # Converte a temperatura para Celsius\n",
        "            temp_celsius = kelvin_para_celsius(temp_kelvin)\n",
        "\n",
        "            # Chama a função que determina a estação do ano a partir da data\n",
        "            estacao = estacao_do_ano(dia, mes)\n",
        "\n",
        "            # Adiciona uma linha com cada coluna para cada plataforma\n",
        "            unico_df = pd.concat([unico_df, pd.DataFrame({\n",
        "                      'Plataforma': plataforma,\n",
        "                      'Velocidade_Vento_u_m/s': vento_u,\n",
        "                      'Velocidade_Vento_v_m/s': vento_v,\n",
        "                      'Velocidade_Vento_resultante_m/s': vento_resultante,\n",
        "                      'Temperatura_K': temp_kelvin,\n",
        "                      'Temperatura_C': temp_celsius,\n",
        "                      'Dia': dia,\n",
        "                      'Mês': mes,\n",
        "                      'Ano': ano,\n",
        "                      'Estação_do_Ano': estacao\n",
        "                  }, index=[0])], ignore_index=True)\n",
        "\n",
        "\n",
        "          #Adiciona as colunas de hora\n",
        "          unico_df['Horário_Brasília'] = hora\n",
        "          unico_df['Horário_UTC'] = hora_utc\n",
        "\n",
        "          # Adiciona o DataFrame unico atual ao DataFrame da hora atual\n",
        "          hora_df = pd.concat([hora_df, unico_df], ignore_index=True)\n",
        "\n",
        "        # Adiciona a coluna de pressão\n",
        "        hora_df['Nível_de_Pressão_hPa'] = int(nivel*10)\n",
        "\n",
        "        # Calcula a altura correspondente ao nível de pressão atual\n",
        "        altura = calcular_altura(PA, k, nivel, g)\n",
        "        # Adiciona a coluna de altura\n",
        "        hora_df['Altitude_m'] = altura\n",
        "\n",
        "        # Adiciona o DataFrame da hora atual ao DataFrame de nível da pressão atual\n",
        "        nivel_df = pd.concat([nivel_df, hora_df], ignore_index=True)\n",
        "\n",
        "      # Adiciona a coluna de dia\n",
        "      nivel_df['Dia'] = dia\n",
        "      # Adiciona o DataFrame do nível de pressão atual ao DataFrame do dia atual\n",
        "      dia_df = pd.concat([dia_df, nivel_df], ignore_index=True)\n",
        "\n",
        "    # Adiciona a coluna de mês\n",
        "    dia_df['Mês'] = mes\n",
        "    # Adiciona o DataFrame do dia atual ao DataFrame do mês atual\n",
        "    mes_df = pd.concat([mes_df, dia_df], ignore_index=True)\n",
        "\n",
        "  # Adiciona a coluna de ano\n",
        "  mes_df['Ano'] = ano\n",
        "  # Adiciona o DataFrame do nível do mês atual ao DataFrame combinado\n",
        "  ano_df = pd.concat([ano_df, mes_df], ignore_index=True)\n",
        "\n",
        "  # Fecha o arquivo NetCDF\n",
        "  ds.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Criar a coluna 'Data' a partir das colunas 'Ano', 'Mês' e 'Dia'\n",
        "ano_df['Data'] = pd.to_datetime(ano_df[['Ano', 'Mês', 'Dia']].rename(columns={'Ano':'year', 'Mês':'month', 'Dia':'day'}), errors='coerce') # Rename columns to match expected names\n",
        "\n",
        "# Remover as colunas 'Ano', 'Mês' e 'Dia'\n",
        "ano_df = ano_df.drop(columns=['Ano', 'Mês', 'Dia'])\n",
        "\n",
        "# Ajusta a ordem das colunas\n",
        "ano_df = ano_df[['Plataforma', 'Nível_de_Pressão_hPa', 'Altitude_m', 'Estação_do_Ano', 'Data', 'Horário_Brasília', 'Horário_UTC',\n",
        "                           'Velocidade_Vento_u_m/s', 'Velocidade_Vento_v_m/s', 'Velocidade_Vento_resultante_m/s', 'Temperatura_K', 'Temperatura_C']]\n",
        "\n",
        "# Salvar o DataFrame combinado como um arquivo CSV\n",
        "ano_df.to_csv(arquivo_csv, encoding='utf-8', index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NFRbvT0jlpY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76cd726c-4cbf-408d-d42a-37df2ec58e0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data inválida: 29/2/2018\n",
            "Data inválida: 30/2/2018\n",
            "Data inválida: 31/2/2018\n",
            "Data inválida: 31/4/2018\n",
            "Data inválida: 31/6/2018\n",
            "Data inválida: 31/9/2018\n",
            "Data inválida: 31/11/2018\n",
            "Data inválida: 29/2/2019\n",
            "Data inválida: 30/2/2019\n",
            "Data inválida: 31/2/2019\n",
            "Data inválida: 31/4/2019\n",
            "Data inválida: 31/6/2019\n",
            "Data inválida: 31/9/2019\n",
            "Data inválida: 31/11/2019\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Anos 2018-2019 --------------------------------------------------------------------\n",
        "'''\n",
        "\n",
        "i = 4\n",
        "\n",
        "arquivo_nc = lista_arq_era5[i]\n",
        "arquivo_csv = lista_arq_csv[i]\n",
        "\n",
        "# Carrega o arquivo NetCDF usando xarray\n",
        "ds = xr.open_dataset(arquivo_nc, engine='h5netcdf')\n",
        "\n",
        "# Renomeia a coordenada 'valid_time' para 'time'\n",
        "ds = ds.rename({'valid_time': 'time'})\n",
        "\n",
        "anos = arquivos_era5[arquivo_nc]\n",
        "\n",
        "ano_df = pd.DataFrame()\n",
        "\n",
        "# Nomeia o índice do DataFrame\n",
        "ano_df.index.name = 'Índice'\n",
        "\n",
        "\n",
        "# Loop sobre cada ano\n",
        "for ano in anos:\n",
        "\n",
        "  # Cria um DataFrame vazio para armazenar os resultados combinados dos meses\n",
        "  mes_df = pd.DataFrame()\n",
        "\n",
        "  # Loop sobre cada mês\n",
        "  for mes in meses:\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados combinados dos dias\n",
        "    dia_df = pd.DataFrame()\n",
        "\n",
        "    # Loop sobre cada dia\n",
        "    for dia in dias:\n",
        "\n",
        "      # Verifica se a data existe\n",
        "      if not data_valida(dia, mes, ano):\n",
        "        print(f\"Data inválida: {dia}/{mes}/{ano}\")\n",
        "        continue  # Pula esta iteração se o dia não for válido\n",
        "\n",
        "      # Cria um DataFrame vazio para armazenar os resultados combinados dos níveis de pressão\n",
        "      nivel_df = pd.DataFrame()\n",
        "\n",
        "      # Loop sobre cada nível de pressão\n",
        "      for nivel in niveis_pressao:\n",
        "\n",
        "        # Cria um DataFrame vazio para armazenar os resultados combinados das horas\n",
        "        hora_df = pd.DataFrame()\n",
        "\n",
        "        # Loop sobre cada hora\n",
        "        for hora in horas:\n",
        "\n",
        "          #Função para obter a hora UTC (Tempo Universal Coordenado) a partir da hora de Brasília\n",
        "          hora_utc = brasilia_para_utc(hora)\n",
        "\n",
        "          # Filtros\n",
        "          filtra_hora = ds.time.dt.strftime('%H:%M') == hora_utc\n",
        "          filtra_nivel = ds['pressure_level'] == nivel*10\n",
        "          filtra_dia = ds.time.dt.day == dia\n",
        "          filtra_mes = ds.time.dt.month == mes\n",
        "          filtra_ano = ds.time.dt.year == ano\n",
        "\n",
        "          # Aplicação dos filtros com where\n",
        "          ds_f = ds.where(filtra_hora & filtra_nivel & filtra_dia & filtra_mes & filtra_ano, drop=True)\n",
        "\n",
        "          # DataArray das velocidades\n",
        "          u = ds_f['u']\n",
        "          v = ds_f['v']\n",
        "\n",
        "          # Calcula a velocidade resultante do vento (wspd)\n",
        "          wspd = (u**2 + v**2)**0.5\n",
        "\n",
        "          # DataArray das temperaturas\n",
        "          temp = ds_f['t']\n",
        "\n",
        "          # Cria um DataFrame vazio para armazenar os resultados combinados das plataformas\n",
        "          unico_df = pd.DataFrame()\n",
        "\n",
        "          # Loop sobre cada plataforma\n",
        "          for plataforma, (lat, lon) in plataformas.items():\n",
        "\n",
        "            # Interpola o valor das componentes da velocidade do vento\n",
        "            vento_u = u.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "            vento_v = v.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "            # Interpola o valor da resultante da velocidade do vento\n",
        "            vento_resultante = wspd.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "\n",
        "            # Interpola o valor da temperatura em Kelvin\n",
        "            temp_kelvin = temp.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "            # Converte a temperatura para Celsius\n",
        "            temp_celsius = kelvin_para_celsius(temp_kelvin)\n",
        "\n",
        "            # Chama a função que determina a estação do ano a partir da data\n",
        "            estacao = estacao_do_ano(dia, mes)\n",
        "\n",
        "            # Adiciona uma linha com cada coluna para cada plataforma\n",
        "            unico_df = pd.concat([unico_df, pd.DataFrame({\n",
        "                      'Plataforma': plataforma,\n",
        "                      'Velocidade_Vento_u_m/s': vento_u,\n",
        "                      'Velocidade_Vento_v_m/s': vento_v,\n",
        "                      'Velocidade_Vento_resultante_m/s': vento_resultante,\n",
        "                      'Temperatura_K': temp_kelvin,\n",
        "                      'Temperatura_C': temp_celsius,\n",
        "                      'Dia': dia,\n",
        "                      'Mês': mes,\n",
        "                      'Ano': ano,\n",
        "                      'Estação_do_Ano': estacao\n",
        "                  }, index=[0])], ignore_index=True)\n",
        "\n",
        "\n",
        "          #Adiciona as colunas de hora\n",
        "          unico_df['Horário_Brasília'] = hora\n",
        "          unico_df['Horário_UTC'] = hora_utc\n",
        "\n",
        "          # Adiciona o DataFrame unico atual ao DataFrame da hora atual\n",
        "          hora_df = pd.concat([hora_df, unico_df], ignore_index=True)\n",
        "\n",
        "        # Adiciona a coluna de pressão\n",
        "        hora_df['Nível_de_Pressão_hPa'] = int(nivel*10)\n",
        "\n",
        "        # Calcula a altura correspondente ao nível de pressão atual\n",
        "        altura = calcular_altura(PA, k, nivel, g)\n",
        "        # Adiciona a coluna de altura\n",
        "        hora_df['Altitude_m'] = altura\n",
        "\n",
        "        # Adiciona o DataFrame da hora atual ao DataFrame de nível da pressão atual\n",
        "        nivel_df = pd.concat([nivel_df, hora_df], ignore_index=True)\n",
        "\n",
        "      # Adiciona a coluna de dia\n",
        "      nivel_df['Dia'] = dia\n",
        "      # Adiciona o DataFrame do nível de pressão atual ao DataFrame do dia atual\n",
        "      dia_df = pd.concat([dia_df, nivel_df], ignore_index=True)\n",
        "\n",
        "    # Adiciona a coluna de mês\n",
        "    dia_df['Mês'] = mes\n",
        "    # Adiciona o DataFrame do dia atual ao DataFrame do mês atual\n",
        "    mes_df = pd.concat([mes_df, dia_df], ignore_index=True)\n",
        "\n",
        "  # Adiciona a coluna de ano\n",
        "  mes_df['Ano'] = ano\n",
        "  # Adiciona o DataFrame do nível do mês atual ao DataFrame combinado\n",
        "  ano_df = pd.concat([ano_df, mes_df], ignore_index=True)\n",
        "\n",
        "  # Fecha o arquivo NetCDF\n",
        "  ds.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Criar a coluna 'Data' a partir das colunas 'Ano', 'Mês' e 'Dia'\n",
        "ano_df['Data'] = pd.to_datetime(ano_df[['Ano', 'Mês', 'Dia']].rename(columns={'Ano':'year', 'Mês':'month', 'Dia':'day'}), errors='coerce') # Rename columns to match expected names\n",
        "\n",
        "# Remover as colunas 'Ano', 'Mês' e 'Dia'\n",
        "ano_df = ano_df.drop(columns=['Ano', 'Mês', 'Dia'])\n",
        "\n",
        "# Ajusta a ordem das colunas\n",
        "ano_df = ano_df[['Plataforma', 'Nível_de_Pressão_hPa', 'Altitude_m', 'Estação_do_Ano', 'Data', 'Horário_Brasília', 'Horário_UTC',\n",
        "                           'Velocidade_Vento_u_m/s', 'Velocidade_Vento_v_m/s', 'Velocidade_Vento_resultante_m/s', 'Temperatura_K', 'Temperatura_C']]\n",
        "\n",
        "# Salvar o DataFrame combinado como um arquivo CSV\n",
        "ano_df.to_csv(arquivo_csv, encoding='utf-8', index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6q1NB7-Djnkh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb9eff6f-bb9f-4ce9-de4b-ef6704554c4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data inválida: 30/2/2020\n",
            "Data inválida: 31/2/2020\n",
            "Data inválida: 31/4/2020\n",
            "Data inválida: 31/6/2020\n",
            "Data inválida: 31/9/2020\n",
            "Data inválida: 31/11/2020\n",
            "Data inválida: 29/2/2021\n",
            "Data inválida: 30/2/2021\n",
            "Data inválida: 31/2/2021\n",
            "Data inválida: 31/4/2021\n",
            "Data inválida: 31/6/2021\n",
            "Data inválida: 31/9/2021\n",
            "Data inválida: 31/11/2021\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Anos 2020-2021 --------------------------------------------------------------------\n",
        "'''\n",
        "\n",
        "i = 5\n",
        "\n",
        "arquivo_nc = lista_arq_era5[i]\n",
        "arquivo_csv = lista_arq_csv[i]\n",
        "\n",
        "# Carrega o arquivo NetCDF usando xarray\n",
        "ds = xr.open_dataset(arquivo_nc, engine='h5netcdf')\n",
        "\n",
        "# Renomeia a coordenada 'valid_time' para 'time'\n",
        "ds = ds.rename({'valid_time': 'time'})\n",
        "\n",
        "anos = arquivos_era5[arquivo_nc]\n",
        "\n",
        "ano_df = pd.DataFrame()\n",
        "\n",
        "# Nomeia o índice do DataFrame\n",
        "ano_df.index.name = 'Índice'\n",
        "\n",
        "\n",
        "# Loop sobre cada ano\n",
        "for ano in anos:\n",
        "\n",
        "  # Cria um DataFrame vazio para armazenar os resultados combinados dos meses\n",
        "  mes_df = pd.DataFrame()\n",
        "\n",
        "  # Loop sobre cada mês\n",
        "  for mes in meses:\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados combinados dos dias\n",
        "    dia_df = pd.DataFrame()\n",
        "\n",
        "    # Loop sobre cada dia\n",
        "    for dia in dias:\n",
        "\n",
        "      # Verifica se a data existe\n",
        "      if not data_valida(dia, mes, ano):\n",
        "        print(f\"Data inválida: {dia}/{mes}/{ano}\")\n",
        "        continue  # Pula esta iteração se o dia não for válido\n",
        "\n",
        "      # Cria um DataFrame vazio para armazenar os resultados combinados dos níveis de pressão\n",
        "      nivel_df = pd.DataFrame()\n",
        "\n",
        "      # Loop sobre cada nível de pressão\n",
        "      for nivel in niveis_pressao:\n",
        "\n",
        "        # Cria um DataFrame vazio para armazenar os resultados combinados das horas\n",
        "        hora_df = pd.DataFrame()\n",
        "\n",
        "        # Loop sobre cada hora\n",
        "        for hora in horas:\n",
        "\n",
        "          #Função para obter a hora UTC (Tempo Universal Coordenado) a partir da hora de Brasília\n",
        "          hora_utc = brasilia_para_utc(hora)\n",
        "\n",
        "          # Filtros\n",
        "          filtra_hora = ds.time.dt.strftime('%H:%M') == hora_utc\n",
        "          filtra_nivel = ds['pressure_level'] == nivel*10\n",
        "          filtra_dia = ds.time.dt.day == dia\n",
        "          filtra_mes = ds.time.dt.month == mes\n",
        "          filtra_ano = ds.time.dt.year == ano\n",
        "\n",
        "          # Aplicação dos filtros com where\n",
        "          ds_f = ds.where(filtra_hora & filtra_nivel & filtra_dia & filtra_mes & filtra_ano, drop=True)\n",
        "\n",
        "          # DataArray das velocidades\n",
        "          u = ds_f['u']\n",
        "          v = ds_f['v']\n",
        "\n",
        "          # Calcula a velocidade resultante do vento (wspd)\n",
        "          wspd = (u**2 + v**2)**0.5\n",
        "\n",
        "          # DataArray das temperaturas\n",
        "          temp = ds_f['t']\n",
        "\n",
        "          # Cria um DataFrame vazio para armazenar os resultados combinados das plataformas\n",
        "          unico_df = pd.DataFrame()\n",
        "\n",
        "          # Loop sobre cada plataforma\n",
        "          for plataforma, (lat, lon) in plataformas.items():\n",
        "\n",
        "            # Interpola o valor das componentes da velocidade do vento\n",
        "            vento_u = u.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "            vento_v = v.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "            # Interpola o valor da resultante da velocidade do vento\n",
        "            vento_resultante = wspd.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "\n",
        "            # Interpola o valor da temperatura em Kelvin\n",
        "            temp_kelvin = temp.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "            # Converte a temperatura para Celsius\n",
        "            temp_celsius = kelvin_para_celsius(temp_kelvin)\n",
        "\n",
        "            # Chama a função que determina a estação do ano a partir da data\n",
        "            estacao = estacao_do_ano(dia, mes)\n",
        "\n",
        "            # Adiciona uma linha com cada coluna para cada plataforma\n",
        "            unico_df = pd.concat([unico_df, pd.DataFrame({\n",
        "                      'Plataforma': plataforma,\n",
        "                      'Velocidade_Vento_u_m/s': vento_u,\n",
        "                      'Velocidade_Vento_v_m/s': vento_v,\n",
        "                      'Velocidade_Vento_resultante_m/s': vento_resultante,\n",
        "                      'Temperatura_K': temp_kelvin,\n",
        "                      'Temperatura_C': temp_celsius,\n",
        "                      'Dia': dia,\n",
        "                      'Mês': mes,\n",
        "                      'Ano': ano,\n",
        "                      'Estação_do_Ano': estacao\n",
        "                  }, index=[0])], ignore_index=True)\n",
        "\n",
        "\n",
        "          #Adiciona as colunas de hora\n",
        "          unico_df['Horário_Brasília'] = hora\n",
        "          unico_df['Horário_UTC'] = hora_utc\n",
        "\n",
        "          # Adiciona o DataFrame unico atual ao DataFrame da hora atual\n",
        "          hora_df = pd.concat([hora_df, unico_df], ignore_index=True)\n",
        "\n",
        "        # Adiciona a coluna de pressão\n",
        "        hora_df['Nível_de_Pressão_hPa'] = int(nivel*10)\n",
        "\n",
        "        # Calcula a altura correspondente ao nível de pressão atual\n",
        "        altura = calcular_altura(PA, k, nivel, g)\n",
        "        # Adiciona a coluna de altura\n",
        "        hora_df['Altitude_m'] = altura\n",
        "\n",
        "        # Adiciona o DataFrame da hora atual ao DataFrame de nível da pressão atual\n",
        "        nivel_df = pd.concat([nivel_df, hora_df], ignore_index=True)\n",
        "\n",
        "      # Adiciona a coluna de dia\n",
        "      nivel_df['Dia'] = dia\n",
        "      # Adiciona o DataFrame do nível de pressão atual ao DataFrame do dia atual\n",
        "      dia_df = pd.concat([dia_df, nivel_df], ignore_index=True)\n",
        "\n",
        "    # Adiciona a coluna de mês\n",
        "    dia_df['Mês'] = mes\n",
        "    # Adiciona o DataFrame do dia atual ao DataFrame do mês atual\n",
        "    mes_df = pd.concat([mes_df, dia_df], ignore_index=True)\n",
        "\n",
        "  # Adiciona a coluna de ano\n",
        "  mes_df['Ano'] = ano\n",
        "  # Adiciona o DataFrame do nível do mês atual ao DataFrame combinado\n",
        "  ano_df = pd.concat([ano_df, mes_df], ignore_index=True)\n",
        "\n",
        "  # Fecha o arquivo NetCDF\n",
        "  ds.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Criar a coluna 'Data' a partir das colunas 'Ano', 'Mês' e 'Dia'\n",
        "ano_df['Data'] = pd.to_datetime(ano_df[['Ano', 'Mês', 'Dia']].rename(columns={'Ano':'year', 'Mês':'month', 'Dia':'day'}), errors='coerce') # Rename columns to match expected names\n",
        "\n",
        "# Remover as colunas 'Ano', 'Mês' e 'Dia'\n",
        "ano_df = ano_df.drop(columns=['Ano', 'Mês', 'Dia'])\n",
        "\n",
        "# Ajusta a ordem das colunas\n",
        "ano_df = ano_df[['Plataforma', 'Nível_de_Pressão_hPa', 'Altitude_m', 'Estação_do_Ano', 'Data', 'Horário_Brasília', 'Horário_UTC',\n",
        "                           'Velocidade_Vento_u_m/s', 'Velocidade_Vento_v_m/s', 'Velocidade_Vento_resultante_m/s', 'Temperatura_K', 'Temperatura_C']]\n",
        "\n",
        "# Salvar o DataFrame combinado como um arquivo CSV\n",
        "ano_df.to_csv(arquivo_csv, encoding='utf-8', index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JZQ1y0JjppR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34392c22-14ed-4e65-9b69-d85f93da306f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data inválida: 29/2/2022\n",
            "Data inválida: 30/2/2022\n",
            "Data inválida: 31/2/2022\n",
            "Data inválida: 31/4/2022\n",
            "Data inválida: 31/6/2022\n",
            "Data inválida: 31/9/2022\n",
            "Data inválida: 31/11/2022\n",
            "Data inválida: 29/2/2023\n",
            "Data inválida: 30/2/2023\n",
            "Data inválida: 31/2/2023\n",
            "Data inválida: 31/4/2023\n",
            "Data inválida: 31/6/2023\n",
            "Data inválida: 31/9/2023\n",
            "Data inválida: 31/11/2023\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Anos 2022-2023 --------------------------------------------------------------------\n",
        "'''\n",
        "\n",
        "i = 6\n",
        "\n",
        "arquivo_nc = lista_arq_era5[i]\n",
        "arquivo_csv = lista_arq_csv[i]\n",
        "\n",
        "# Carrega o arquivo NetCDF usando xarray\n",
        "ds = xr.open_dataset(arquivo_nc, engine='h5netcdf')\n",
        "\n",
        "# Renomeia a coordenada 'valid_time' para 'time'\n",
        "ds = ds.rename({'valid_time': 'time'})\n",
        "\n",
        "anos = arquivos_era5[arquivo_nc]\n",
        "\n",
        "ano_df = pd.DataFrame()\n",
        "\n",
        "# Nomeia o índice do DataFrame\n",
        "ano_df.index.name = 'Índice'\n",
        "\n",
        "\n",
        "# Loop sobre cada ano\n",
        "for ano in anos:\n",
        "\n",
        "  # Cria um DataFrame vazio para armazenar os resultados combinados dos meses\n",
        "  mes_df = pd.DataFrame()\n",
        "\n",
        "  # Loop sobre cada mês\n",
        "  for mes in meses:\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados combinados dos dias\n",
        "    dia_df = pd.DataFrame()\n",
        "\n",
        "    # Loop sobre cada dia\n",
        "    for dia in dias:\n",
        "\n",
        "      # Verifica se a data existe\n",
        "      if not data_valida(dia, mes, ano):\n",
        "        print(f\"Data inválida: {dia}/{mes}/{ano}\")\n",
        "        continue  # Pula esta iteração se o dia não for válido\n",
        "\n",
        "      # Cria um DataFrame vazio para armazenar os resultados combinados dos níveis de pressão\n",
        "      nivel_df = pd.DataFrame()\n",
        "\n",
        "      # Loop sobre cada nível de pressão\n",
        "      for nivel in niveis_pressao:\n",
        "\n",
        "        # Cria um DataFrame vazio para armazenar os resultados combinados das horas\n",
        "        hora_df = pd.DataFrame()\n",
        "\n",
        "        # Loop sobre cada hora\n",
        "        for hora in horas:\n",
        "\n",
        "          #Função para obter a hora UTC (Tempo Universal Coordenado) a partir da hora de Brasília\n",
        "          hora_utc = brasilia_para_utc(hora)\n",
        "\n",
        "          # Filtros\n",
        "          filtra_hora = ds.time.dt.strftime('%H:%M') == hora_utc\n",
        "          filtra_nivel = ds['pressure_level'] == nivel*10\n",
        "          filtra_dia = ds.time.dt.day == dia\n",
        "          filtra_mes = ds.time.dt.month == mes\n",
        "          filtra_ano = ds.time.dt.year == ano\n",
        "\n",
        "          # Aplicação dos filtros com where\n",
        "          ds_f = ds.where(filtra_hora & filtra_nivel & filtra_dia & filtra_mes & filtra_ano, drop=True)\n",
        "\n",
        "          # DataArray das velocidades\n",
        "          u = ds_f['u']\n",
        "          v = ds_f['v']\n",
        "\n",
        "          # Calcula a velocidade resultante do vento (wspd)\n",
        "          wspd = (u**2 + v**2)**0.5\n",
        "\n",
        "          # DataArray das temperaturas\n",
        "          temp = ds_f['t']\n",
        "\n",
        "          # Cria um DataFrame vazio para armazenar os resultados combinados das plataformas\n",
        "          unico_df = pd.DataFrame()\n",
        "\n",
        "          # Loop sobre cada plataforma\n",
        "          for plataforma, (lat, lon) in plataformas.items():\n",
        "\n",
        "            # Interpola o valor das componentes da velocidade do vento\n",
        "            vento_u = u.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "            vento_v = v.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "            # Interpola o valor da resultante da velocidade do vento\n",
        "            vento_resultante = wspd.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "\n",
        "            # Interpola o valor da temperatura em Kelvin\n",
        "            temp_kelvin = temp.interp(latitude=lat, longitude=lon, method='nearest').values.item()\n",
        "            # Converte a temperatura para Celsius\n",
        "            temp_celsius = kelvin_para_celsius(temp_kelvin)\n",
        "\n",
        "            # Chama a função que determina a estação do ano a partir da data\n",
        "            estacao = estacao_do_ano(dia, mes)\n",
        "\n",
        "            # Adiciona uma linha com cada coluna para cada plataforma\n",
        "            unico_df = pd.concat([unico_df, pd.DataFrame({\n",
        "                      'Plataforma': plataforma,\n",
        "                      'Velocidade_Vento_u_m/s': vento_u,\n",
        "                      'Velocidade_Vento_v_m/s': vento_v,\n",
        "                      'Velocidade_Vento_resultante_m/s': vento_resultante,\n",
        "                      'Temperatura_K': temp_kelvin,\n",
        "                      'Temperatura_C': temp_celsius,\n",
        "                      'Dia': dia,\n",
        "                      'Mês': mes,\n",
        "                      'Ano': ano,\n",
        "                      'Estação_do_Ano': estacao\n",
        "                  }, index=[0])], ignore_index=True)\n",
        "\n",
        "\n",
        "          #Adiciona as colunas de hora\n",
        "          unico_df['Horário_Brasília'] = hora\n",
        "          unico_df['Horário_UTC'] = hora_utc\n",
        "\n",
        "          # Adiciona o DataFrame unico atual ao DataFrame da hora atual\n",
        "          hora_df = pd.concat([hora_df, unico_df], ignore_index=True)\n",
        "\n",
        "        # Adiciona a coluna de pressão\n",
        "        hora_df['Nível_de_Pressão_hPa'] = int(nivel*10)\n",
        "\n",
        "        # Calcula a altura correspondente ao nível de pressão atual\n",
        "        altura = calcular_altura(PA, k, nivel, g)\n",
        "        # Adiciona a coluna de altura\n",
        "        hora_df['Altitude_m'] = altura\n",
        "\n",
        "        # Adiciona o DataFrame da hora atual ao DataFrame de nível da pressão atual\n",
        "        nivel_df = pd.concat([nivel_df, hora_df], ignore_index=True)\n",
        "\n",
        "      # Adiciona a coluna de dia\n",
        "      nivel_df['Dia'] = dia\n",
        "      # Adiciona o DataFrame do nível de pressão atual ao DataFrame do dia atual\n",
        "      dia_df = pd.concat([dia_df, nivel_df], ignore_index=True)\n",
        "\n",
        "    # Adiciona a coluna de mês\n",
        "    dia_df['Mês'] = mes\n",
        "    # Adiciona o DataFrame do dia atual ao DataFrame do mês atual\n",
        "    mes_df = pd.concat([mes_df, dia_df], ignore_index=True)\n",
        "\n",
        "  # Adiciona a coluna de ano\n",
        "  mes_df['Ano'] = ano\n",
        "  # Adiciona o DataFrame do nível do mês atual ao DataFrame combinado\n",
        "  ano_df = pd.concat([ano_df, mes_df], ignore_index=True)\n",
        "\n",
        "  # Fecha o arquivo NetCDF\n",
        "  ds.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Criar a coluna 'Data' a partir das colunas 'Ano', 'Mês' e 'Dia'\n",
        "ano_df['Data'] = pd.to_datetime(ano_df[['Ano', 'Mês', 'Dia']].rename(columns={'Ano':'year', 'Mês':'month', 'Dia':'day'}), errors='coerce') # Rename columns to match expected names\n",
        "\n",
        "# Remover as colunas 'Ano', 'Mês' e 'Dia'\n",
        "ano_df = ano_df.drop(columns=['Ano', 'Mês', 'Dia'])\n",
        "\n",
        "# Ajusta a ordem das colunas\n",
        "ano_df = ano_df[['Plataforma', 'Nível_de_Pressão_hPa', 'Altitude_m', 'Estação_do_Ano', 'Data', 'Horário_Brasília', 'Horário_UTC',\n",
        "                           'Velocidade_Vento_u_m/s', 'Velocidade_Vento_v_m/s', 'Velocidade_Vento_resultante_m/s', 'Temperatura_K', 'Temperatura_C']]\n",
        "\n",
        "# Salvar o DataFrame combinado como um arquivo CSV\n",
        "ano_df.to_csv(arquivo_csv, encoding='utf-8', index=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjM7P8BU5NKLvARsgTZqEC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}